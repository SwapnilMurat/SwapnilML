# Datasheet Template

As far as you can, complete the model datasheet. If you have got the data from the internet, you may not have all the information you need, but make sure you include all the information you do have. 

## Motivation

- For what purpose was the dataset created? 
- Who created the dataset (e.g., which team, research group) and on behalf of which entity (e.g., company, institution, organization)? Who funded the creation of the dataset?

LaMDA was created to improve the performance of large language models on a variety of tasks, including text generation, translation, and question answering. It was developed by Google AI, and its creation was funded by Google.
 
## Composition

- What do the instances that comprise the dataset represent (e.g., documents, photos, people, countries)? 
- How many instances of each type are there? 
- Is there any missing data?
- Does the dataset contain data that might be considered confidential (e.g., data that is protected by legal privilege or by    doctor–patient confidentiality, data that includes the content of individuals’ non-public communications)?

LaMDA is a neural network model that is trained on a massive dataset of text and code. The instances that comprise the dataset represent a variety of different types of text, including news articles, books, code, and web pages. The exact number of instances in the dataset is not publicly known, but it is estimated to be in the trillions. There is some missing data in the dataset, but it is not believed to have a significant impact on the model's performance. The dataset does not contain any data that is considered confidential.


## Collection process

- How was the data acquired? 
- If the data is a sample of a larger subset, what was the sampling strategy? 
- Over what time frame was the data collected?

The data for LaMDA was collected from a variety of public sources, including the Common Crawl, Wikipedia, and GitHub. The sampling strategy for the dataset is not publicly known, but it is believed to be representative of the overall distribution of text on the internet. The data was collected over a period of several years.

## Preprocessing/cleaning/labelling

- Was any preprocessing/cleaning/labeling of the data done (e.g., discretization or bucketing, tokenization, part-of-speech tagging, SIFT feature extraction, removal of instances, processing of missing values)? If so, please provide a description. If not, you may skip the remaining questions in this section. 
- Was the “raw” data saved in addition to the preprocessed/cleaned/labeled data (e.g., to support unanticipated future uses)? 

The data for LaMDA was preprocessed and cleaned before being used to train the model. This included removing duplicates, normalizing text, and tokenizing sentences. The data was not labeled, as LaMDA is a self-supervised learning model.
 
## Uses

- What other tasks could the dataset be used for? 
- Is there anything about the composition of the dataset or the way it was collected and preprocessed/cleaned/labeled that might impact future uses? For example, is there anything that a dataset consumer might need to know to avoid uses that could result in unfair treatment of individuals or groups (e.g., stereotyping, quality of service issues) or other risks or harms (e.g., legal risks, financial harms)? If so, please provide a description. Is there anything a dataset consumer could do to mitigate these risks or harms? 
- Are there tasks for which the dataset should not be used? If so, please provide a description.

LaMDA can be used for a variety of tasks, including text generation, translation, and question answering. It can also be used to generate different creative text formats, like poems, code, scripts, musical pieces, email, letters, etc.

The dataset used to train LaMDA could potentially be used for other tasks, such as sentiment analysis and topic modeling. However, it is important to note that the dataset is not representative of the entire distribution of text on the internet, and therefore it may not be appropriate for all tasks.

There are some tasks for which LaMDA should not be used. For example, LaMDA should not be used to generate hate speech or other harmful content. It should also not be used to generate content that is intended to deceive or mislead others.

## Distribution

- How has the dataset already been distributed? 
- Is it subject to any copyright or other intellectual property (IP) license, and/or under applicable terms of use (ToU)?  

LaMDA is not currently available for public download. However, it is possible to request access to the model through Google AI.

LaMDA is subject to Google's AI Principles, which state that AI should be used in a way that is socially beneficial, accountable, and aligned with human values.

## Maintenance

- Who maintains the dataset?

LaMDA is maintained by a team of engineers and scientists at Google AI. The team is responsible for collecting new data, training new models, and fixing bugs.

